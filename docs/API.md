# üîå API Documentation - Clauger RSE Web

Documentation compl√®te de l'API du chatbot IA et des endpoints disponibles.

---

## üìã Table des Mati√®res

1. [Chatbot API](#chatbot-api)
2. [Mod√®les IA](#mod√®les-ia)
3. [S√©curit√©](#s√©curit√©)
4. [Codes d'Erreur](#codes-derreur)
5. [Exemples d'Utilisation](#exemples-dutilisation)
6. [Rate Limiting](#rate-limiting)

---

## ü§ñ Chatbot API

### POST `/api/chat`

Endpoint principal pour interagir avec l'assistant IA Claude.

#### Request

**Headers:**
```http
Content-Type: application/json
```

**Body:**
```typescript
{
  messages: UIMessage[],      // Historique de conversation
  currentPage?: number        // Page courante du rapport (optionnel)
}
```

**UIMessage Type:**
```typescript
interface UIMessage {
  role: 'user' | 'assistant'
  content: string
  id?: string
  createdAt?: Date
}
```

#### Response

**Success (200):**

Streaming response (Server-Sent Events) avec les chunks de texte g√©n√©r√©s par Claude.

```
Format: text/event-stream
```

**Response Headers:**
```http
Content-Type: text/event-stream
Cache-Control: no-cache
Connection: keep-alive
```

**Stream Events:**
```typescript
// Message chunks
0:"text_chunk_1"
1:"text_chunk_2"
...

// Final message
d:{"finishReason":"stop","usage":{"promptTokens":1234,"completionTokens":567}}
```

#### Example Request

```typescript
const response = await fetch('/api/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    messages: [
      {
        role: 'user',
        content: 'Quel est le score environnemental de Clauger?'
      }
    ],
    currentPage: 15
  })
})

// Handle streaming response
const reader = response.body?.getReader()
const decoder = new TextDecoder()

while (true) {
  const { done, value } = await reader.read()
  if (done) break

  const chunk = decoder.decode(value)
  console.log(chunk) // Process each chunk
}
```

#### Example with useChat Hook

```typescript
import { useChatbot } from '@/hooks/useChatbot'

function MyComponent() {
  const {
    messages,
    input,
    handleInputChange,
    handleSubmit,
    isLoading
  } = useChatbot({ currentPage: 5 })

  return (
    <form onSubmit={handleSubmit}>
      {messages.map(message => (
        <div key={message.id}>
          <strong>{message.role}:</strong> {message.content}
        </div>
      ))}

      <textarea
        value={input}
        onChange={handleInputChange}
        disabled={isLoading}
      />

      <button type="submit" disabled={isLoading}>
        Envoyer
      </button>
    </form>
  )
}
```

---

## üß† Mod√®les IA

L'API utilise un syst√®me de routing intelligent pour s√©lectionner le mod√®le optimal.

### Mod√®les Disponibles

| Mod√®le | ID | Co√ªt Input | Co√ªt Output | Performance |
|--------|----|-----------:|------------:|-------------|
| **Haiku** | `claude-3-5-haiku-20241022` | $0.80/M | $4.00/M | Rapide |
| **Sonnet 4.5** | `claude-sonnet-4-5-20250929` | $3.00/M | $15.00/M | Pr√©cis |

### Routing Automatique

Le syst√®me analyse la complexit√© de la requ√™te et s√©lectionne le mod√®le appropri√©.

**Crit√®res de s√©lection:**

1. **Longueur de la query**
   - < 100 chars ‚Üí score +0
   - 100-200 chars ‚Üí score +1
   - 200-500 chars ‚Üí score +2
   - \> 500 chars ‚Üí score +3

2. **Indicateurs de complexit√©**
   - **Haute** (+5): analyser, comparer, synth√©tiser, tendance, strat√©gie
   - **Moyenne** (+3): expliquer, d√©tailler, diff√©rence, relation
   - **Simple** (-1): quel, combien, o√π, score, liste

3. **Questions multiples**
   - 2 questions ‚Üí score +1
   - 3+ questions ‚Üí score +3

4. **Structure**
   - Conjonctions multiples (et, puis, ainsi que) ‚Üí score +1

**Seuils de d√©cision:**
- Score < 3 ‚Üí **Haiku**
- Score 3-5 ‚Üí **Haiku** (capable)
- Score ‚â• 6 ‚Üí **Sonnet 4.5**

### Extended Thinking

Pour les questions complexes, activez Extended Thinking avec le pr√©fixe `###`:

```
### Analyser en profondeur l'√©volution de l'empreinte carbone de Clauger entre 2022 et 2024
```

**Configuration:**
- Budget: 10,000 tokens de r√©flexion
- Utilisation: Questions n√©cessitant analyse approfondie
- Co√ªt: Inclus dans les tokens de sortie

---

## üõ°Ô∏è S√©curit√©

### Input Validation

Toutes les requ√™tes passent par une validation stricte:

**R√®gles:**
```typescript
{
  minLength: 3,           // Minimum 3 caract√®res
  maxLength: 2000,        // Maximum 2000 caract√®res
  blockedPatterns: [
    /(?:SELECT|DROP|INSERT|UPDATE|DELETE)\s+/i,  // SQL injection
    /<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,  // XSS
    /javascript:/i,       // JavaScript protocol
    /on\w+\s*=/i         // Event handlers
  ]
}
```

**Erreur de validation (400):**
```json
{
  "error": "Votre message contient des caract√®res ou patterns non autoris√©s. Veuillez reformuler.",
  "details": "Detected SQL injection pattern"
}
```

### Content Security Policy

Headers de s√©curit√© appliqu√©s:

```http
Content-Security-Policy:
  script-src 'self' 'nonce-{random}';
  img-src 'self' data: https:;
  connect-src 'self' https://api.anthropic.com;
  default-src 'self';
```

### Resilience

**Circuit Breaker:**
- Seuil: 5 √©checs cons√©cutifs
- Timeout: 60 secondes
- √âtat: CLOSED (normal), OPEN (bloqu√©), HALF_OPEN (test)

**Retry avec Backoff:**
- Max retries: 3
- D√©lai initial: 1000ms
- D√©lai max: 30000ms
- Multiplicateur: 2x
- Jitter: Activ√© (¬±25%)

---

## ‚ö†Ô∏è Codes d'Erreur

### 400 Bad Request

**Cause:** Validation √©chou√©e

```json
{
  "error": "Votre message contient des caract√®res ou patterns non autoris√©s.",
  "details": "Content too long (2500 > 2000)"
}
```

**Solutions:**
- V√©rifier longueur du message (3-2000 chars)
- Supprimer patterns suspects (SQL, script tags)
- Reformuler la question

### 401 Unauthorized

**Cause:** Cl√© API Anthropic invalide ou manquante

```json
{
  "error": "Cl√© API Anthropic invalide. V√©rifiez votre configuration."
}
```

**Solutions:**
- V√©rifier `.env.local` contient `ANTHROPIC_API_KEY`
- V√©rifier validit√© de la cl√© sur console.anthropic.com
- Red√©marrer le serveur apr√®s modification

### 429 Too Many Requests

**Cause:** Rate limit d√©pass√©

```json
{
  "error": "Limite de requ√™tes atteinte. Veuillez r√©essayer dans quelques instants."
}
```

**Client-side (toast):**
```
"Trop de requ√™tes. Veuillez patienter {X}s avant de r√©essayer."
```

**Solutions:**
- Attendre le d√©lai indiqu√©
- R√©duire fr√©quence des requ√™tes
- Limite: 10 requ√™tes/minute par session

### 500 Internal Server Error

**Cause:** Erreur serveur inattendue

```json
{
  "error": "Une erreur est survenue lors du traitement de votre demande.",
  "details": "Network timeout"
}
```

**Solutions:**
- R√©essayer la requ√™te
- V√©rifier connexion internet
- V√©rifier statut API Anthropic (status.anthropic.com)

---

## üö¶ Rate Limiting

### Configuration

**Limite client-side:**
```typescript
{
  maxTokens: 10,          // 10 requ√™tes max
  windowMs: 60000,        // Sur 1 minute
  refillRate: 10,         // Recharge compl√®te toutes les 1min
}
```

### Utilisation

Le hook `useChatbot` g√®re automatiquement le rate limiting:

```typescript
const handleSubmit = async () => {
  const result = await chatRateLimiter.checkAndConsume()

  if (!result.allowed) {
    toast.error('Trop de requ√™tes', {
      description: `Veuillez patienter ${result.retryAfter}s`
    })
    return
  }

  // Envoyer la requ√™te...
}
```

### √âtats

**Tokens disponibles:**
```typescript
interface RateLimitResult {
  allowed: boolean          // Requ√™te autoris√©e?
  remainingTokens: number   // Tokens restants
  retryAfter?: number       // Attente en secondes si bloqu√©
  resetTime?: number        // Timestamp reset complet
}
```

**Exemple de r√©ponse:**
```json
{
  "allowed": false,
  "remainingTokens": 0,
  "retryAfter": 45,
  "resetTime": 1700000000000
}
```

---

## üìä Analytics

### √âv√©nements Track√©s

L'API √©met des √©v√©nements analytics pour monitoring:

**1. Message envoy√©**
```typescript
{
  eventType: 'chat.message.sent',
  properties: {
    queryLength: 123,
    messageCount: 5,
    currentPage: 15,
    modelUsed: 'claude-3-5-haiku-20241022',
    complexityScore: 2,
    estimatedCost: 0.0015
  }
}
```

**2. Contexte construit**
```typescript
{
  eventType: 'chat.context.built',
  properties: {
    sources: ['semantic_chunking', 'scores'],
    sourceCount: 2,
    contextLength: 4500,
    estimatedTokens: 1125,
    buildDuration: 15
  }
}
```

**3. R√©ponse compl√®te**
```typescript
{
  eventType: 'chat.response.completed',
  properties: {
    responseLength: 567,
    inputTokens: 1234,
    outputTokens: 567,
    totalTokens: 1801,
    thinkingUsed: false,
    duration: 2500,
    tokensPerSecond: 227
  }
}
```

**4. Cache metrics**
```typescript
{
  eventType: 'chat.cache.metrics',
  properties: {
    cacheHit: true,
    cacheReadTokens: 1100,
    cacheCreationTokens: 0,
    cacheReadPercentage: 89.1,
    estimatedSavings: 0.0245
  }
}
```

---

## üíæ Prompt Caching

### Configuration

**Cache ephemeral:**
```typescript
{
  cacheControl: {
    type: 'ephemeral'
  }
}
```

### Fonctionnement

**1. Premier appel (cache MISS):**
```
Input tokens: 15,000 (contexte RSE)
Cache creation: 15,000 tokens
Co√ªt: 15,000 √ó $3.00/M = $0.045
```

**2. Appels suivants (cache HIT, < 5min):**
```
Input tokens: 200 (nouvelle question)
Cache read: 15,000 tokens (r√©utilis√©)
Co√ªt: (200 √ó $3.00/M) + (15,000 √ó $0.30/M) = $0.0051
√âconomie: 90%
```

### M√©triques

**Response metadata:**
```typescript
{
  anthropic: {
    cacheReadInputTokens: 15000,      // Tokens lus du cache
    cacheCreationInputTokens: 0,      // Tokens cr√©√©s (1er appel)
  }
}
```

---

## üîß Configuration Avanc√©e

### Variables d'Environnement

```env
# Required
ANTHROPIC_API_KEY=sk-ant-...

# Optional
NEXT_PUBLIC_ANALYTICS_ENABLED=true
NEXT_PUBLIC_RATE_LIMIT_MAX=10
NEXT_PUBLIC_RATE_LIMIT_WINDOW=60000
```

### Personnalisation du Contexte

Modifier `lib/ai/context-builder.ts` pour ajuster le contexte envoy√©:

```typescript
export class ContextBuilder {
  static async buildOptimizedContext(
    query: string,
    currentPage?: number,
    complexity: 'simple' | 'medium' | 'complex' = 'medium'
  ): Promise<ContextResult> {
    // Personnaliser la logique de s√©lection des sources
    const sources = []

    if (complexity === 'simple') {
      sources.push(await this.getSemanticChunks(query, 3))
    } else {
      sources.push(await this.getFullAnalysis())
    }

    return { systemContext, metadata }
  }
}
```

### Personnalisation du Routing

Modifier `lib/ai/model-router.ts` pour ajuster les crit√®res:

```typescript
export class ModelRouter {
  static analyzeComplexity(query: string): ComplexityScore {
    // Personnaliser les indicateurs
    const CUSTOM_INDICATORS = {
      veryComplex: ['analyse critique', '√©valuation approfondie'],
      // ...
    }

    // Ajuster les seuils
    if (score >= 8) return 'complex'
    if (score >= 4) return 'medium'
    return 'simple'
  }
}
```

---

## üìö Ressources

**Documentation Externe:**
- [Anthropic API Docs](https://docs.anthropic.com/)
- [Vercel AI SDK v5](https://sdk.vercel.ai/docs)
- [Next.js App Router](https://nextjs.org/docs/app)

**Code Source:**
- API Route: `app/api/chat/route.ts`
- Context Builder: `lib/ai/context-builder.ts`
- Model Router: `lib/ai/model-router.ts`
- Chatbot Hook: `hooks/useChatbot.ts`

---

**Derni√®re mise √† jour : 15 novembre 2024**
